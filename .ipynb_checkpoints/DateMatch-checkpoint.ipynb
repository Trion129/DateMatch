{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv', delimiter=',', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = [\n",
    "    'samerace', 'pf_o_att', 'pf_o_sin', 'pf_o_int',\n",
    "    'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o',\n",
    "    'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'imprace', 'imprelig',\n",
    "    'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'met'\n",
    "]\n",
    "\n",
    "col1 = df[features]\n",
    "\n",
    "# Fill missing data with zero as it is unfilled in card\n",
    "col1 = col1.fillna(0)\n",
    "col2 = df[['match']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reshape and convert to numpy array\n",
    "col1_np = col1.as_matrix()\n",
    "col2_np = col2.as_matrix()\n",
    "\n",
    "nX_Features = len(features)\n",
    "nY_Features = 1\n",
    "nSamples = 24000\n",
    "\n",
    "col1_reshape = np.resize(col1_np, (nSamples, nX_Features))\n",
    "col2_reshape = np.resize(col2_np, (nSamples, nY_Features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create Batches from data\n",
    "batch_size = 2000\n",
    "\n",
    "Xbatches = np.split(col1_reshape, nSamples // batch_size)\n",
    "Ybatches = np.split(col2_reshape, nSamples // batch_size)\n",
    "batches = list(zip(Xbatches, Ybatches))\n",
    "\n",
    "trainingBatches = batches[:-1]\n",
    "validationBatches = batches[-2:-1]\n",
    "testBatches = batches[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 2600\n",
    "display_result = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input\n",
    "X = tf.placeholder(tf.float32,shape=(None,nX_Features))#[batch size, input_features]\n",
    "#Output\n",
    "Y = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Neurons\n",
    "L1 = 7\n",
    "L2 = 4\n",
    "L3 = 4\n",
    "#Layer1 weights\n",
    "W_fc1 = tf.Variable(tf.random_uniform([nX_Features,L1])) # [input_features,Number of neurons]) \n",
    "b_fc1 = tf.Variable(tf.constant(0.1,shape=[L1]))\n",
    "#Layer2 weights\n",
    "W_fc2 = tf.Variable(tf.random_uniform([L1,L2])) # [Number of neurons in preceding layer,Number of neurons]) \n",
    "b_fc2 = tf.Variable(tf.constant(0.1,shape=[L2]))\n",
    "#Layer3 weights\n",
    "W_fc3 = tf.Variable(tf.random_uniform([L2,L3])) # [Number of neurons in preceding layer,Number of neurons]) \n",
    "b_fc3 = tf.Variable(tf.constant(0.1,shape=[L3]))\n",
    "#Output layer weights\n",
    "W_fO= tf.Variable(tf.random_uniform([L3,nY_Features])) #  [Number of neurons in preceding layer,output_features]) \n",
    "b_fO = tf.Variable(tf.constant(0.1,shape=[nY_Features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Layer 1\n",
    "matmul_fc1=tf.matmul(X, W_fc1) + b_fc1\n",
    "h_fc1 = tf.nn.relu(matmul_fc1)   #ReLU activation\n",
    "#Layer 2\n",
    "matmul_fc2=tf.matmul(h_fc1, W_fc2) + b_fc2\n",
    "h_fc2 = tf.nn.relu(matmul_fc2)   #ReLU activation\n",
    "#Layer 3\n",
    "matmul_fc3=tf.matmul(h_fc2, W_fc3) + b_fc3\n",
    "h_fc3 = tf.nn.relu(matmul_fc3)   #ReLU activation\n",
    "#Output layer\n",
    "matmul_fc4=tf.matmul(h_fc3, W_fO) + b_fO\n",
    "output_layer = matmul_fc4  #linear activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loss function\n",
    "mean_square =  tf.reduce_mean(tf.square(Y-output_layer))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(mean_square)\n",
    "#train_step = tf.train.AdagradOptimizer(learning_rate).minimize(mean_square)\n",
    "#train_step = tf.train.MomentumOptimizer(learning_rate,0.01).minimize(mean_square)\n",
    "#train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(mean_square)\n",
    "#Operation to save variables\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss is: [817754.62] at itertion: 0\n",
      "Validation loss is: [804128.62] at itertion: 0\n",
      "Training loss is: [4.3835778] at itertion: 200\n",
      "Validation loss is: [3.984575] at itertion: 200\n",
      "Training loss is: [4.1193085] at itertion: 400\n",
      "Validation loss is: [3.7031188] at itertion: 400\n",
      "Training loss is: [3.4679291] at itertion: 600\n",
      "Validation loss is: [3.1355882] at itertion: 600\n",
      "Training loss is: [2.313359] at itertion: 800\n",
      "Validation loss is: [2.0947227] at itertion: 800\n",
      "Training loss is: [1.0080471] at itertion: 1000\n",
      "Validation loss is: [0.9139207] at itertion: 1000\n",
      "Training loss is: [0.2885249] at itertion: 1200\n",
      "Validation loss is: [0.27226073] at itertion: 1200\n",
      "Training loss is: [0.14058459] at itertion: 1400\n",
      "Validation loss is: [0.13780767] at itertion: 1400\n",
      "Training loss is: [0.11752845] at itertion: 1600\n",
      "Validation loss is: [0.11301934] at itertion: 1600\n",
      "Training loss is: [0.11600038] at itertion: 1800\n",
      "Validation loss is: [0.10882206] at itertion: 1800\n",
      "Training loss is: [0.11312106] at itertion: 2000\n",
      "Validation loss is: [0.10532539] at itertion: 2000\n",
      "Training loss is: [0.11349706] at itertion: 2200\n",
      "Validation loss is: [0.10562079] at itertion: 2200\n",
      "Training loss is: [0.11410005] at itertion: 2400\n",
      "Validation loss is: [0.10649809] at itertion: 2400\n",
      "Model saved in file: /tmp/datesim.ckpt\n",
      "Final training loss: [0.1222731]\n",
      "Final validation loss: [0.10682666]\n"
     ]
    }
   ],
   "source": [
    "#Initialization and session\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(training_epochs):\n",
    "        first = True\n",
    "        for batch in trainingBatches:\n",
    "            sess.run([train_step], feed_dict={X:batch[0],Y:batch[1]})\n",
    "            if i % display_result == 0 and first:\n",
    "                print(\"Training loss is:\",sess.run([mean_square],feed_dict={X:batch[0],Y:batch[1]}),\"at itertion:\",i)\n",
    "                print(\"Validation loss is:\",sess.run([mean_square],feed_dict={X:validationBatches[0][0],Y:validationBatches[0][1]}),\"at itertion:\",i)\n",
    "                first = False\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \"/tmp/datesim.ckpt\")\n",
    "    print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "    print(\"Final training loss:\",sess.run([mean_square],feed_dict={X:testBatches[0][0],Y:testBatches[0][1]}))\n",
    "    print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:validationBatches[0][0],Y:validationBatches[0][1]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fill 0 to 10 in next values\n",
      "Preference for Attraction by partner:6\n",
      "Preference for Sincerity by partner:8\n",
      "Preference for Intelligence by partner:7\n",
      "Preference for Fun by partner:7\n",
      "Preference for Ambition by partner:8\n",
      "Preference for Shared Interests by partner:5\n",
      "Attraction score by partner:7\n",
      "Sincerity score by partner:8\n",
      "Intelligence score by partner:10\n",
      "Fun score by partner:4\n",
      "Ambition score by partner:10\n",
      "Shared interests score by partner:7\n",
      "Liked by partner:7\n",
      "Probablity candidate will like partner(filled by partner):6\n",
      "Following are filled by candidate:\n",
      "Attraction by candidate:7\n",
      "Sincerity by candidate:9\n",
      "Intelligence by candidate:9\n",
      "Fun by candidate:5\n",
      "Ambition by candidate:7\n",
      "Shared interests by candidate:8\n",
      "How much Liked by candidate:7\n",
      "Fill 0 or 1 for next questions:\n",
      "Did you meet earlier?1\n",
      "Are both of same race?0\n",
      "Importance of race:0\n",
      "Importance of Religion:0\n",
      "Model restored.\n",
      "output: [array([[ 0.17712368]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#Testing\n",
    "#features = [\n",
    "#     'samerace', 'pf_o_att', 'pf_o_sin', 'pf_o_int',\n",
    "#     'pf_o_fun', 'pf_o_amb', 'pf_o_sha', 'attr_o', 'sinc_o', 'intel_o',\n",
    "#     'fun_o', 'amb_o', 'shar_o', 'like_o', 'prob_o', 'imprace', 'imprelig',\n",
    "#     'attr', 'sinc', 'intel', 'fun', 'amb', 'shar', 'like', 'met'\n",
    "# ]\n",
    "print(\"Fill 0 to 10 in next values\")\n",
    "pf_o_att = input(\"Preference for Attraction by partner:\")\n",
    "pf_o_sin = input(\"Preference for Sincerity by partner:\")\n",
    "pf_o_int = input(\"Preference for Intelligence by partner:\")\n",
    "pf_o_fun = input(\"Preference for Fun by partner:\")\n",
    "pf_o_amb = input(\"Preference for Ambition by partner:\")\n",
    "pf_o_sha = input(\"Preference for Shared Interests by partner:\")\n",
    "attr_o = input(\"Attraction score by partner:\")\n",
    "sinc_o = input(\"Sincerity score by partner:\")\n",
    "intel_o = input(\"Intelligence score by partner:\")\n",
    "fun_o = input(\"Fun score by partner:\")\n",
    "amb_o = input(\"Ambition score by partner:\")\n",
    "shar_o = input(\"Shared interests score by partner:\")\n",
    "like_o = input(\"Liked by partner:\")\n",
    "prob_o = input(\"Probablity candidate will like partner(filled by partner):\")\n",
    "print(\"Following are filled by candidate:\")\n",
    "attr = input(\"Attraction by candidate:\")\n",
    "sinc = input(\"Sincerity by candidate:\")\n",
    "intel = input(\"Intelligence by candidate:\")\n",
    "fun = input(\"Fun by candidate:\")\n",
    "amb = input(\"Ambition by candidate:\")\n",
    "shar = input(\"Shared interests by candidate:\")\n",
    "like = input(\"How much Liked by candidate:\")\n",
    "print(\"Fill 0 or 1 for next questions:\")\n",
    "met = input(\"Did you meet earlier?\")\n",
    "samerace = input(\"Are both of same race?\")\n",
    "imprace = input(\"Importance of race:\")\n",
    "imprelig = input(\"Importance of Religion:\")\n",
    "\n",
    "InputX2 = np.asarray([[samerace, pf_o_att, pf_o_sin, pf_o_int, pf_o_fun, pf_o_amb, pf_o_sha,\n",
    "                      attr_o, sinc_o, intel_o, fun_o, amb_o, shar_o, like_o, prob_o,\n",
    "                      imprace, imprelig, attr, sinc, intel, fun, amb, shar, like, met]],dtype=np.float32)\n",
    "InputX1test = np.resize(InputX2,(1,nX_Features))\n",
    "with tf.Session() as sess:\n",
    "    # Restore variables from disk for validation.\n",
    "    saver.restore(sess, \"/tmp/datesim.ckpt\")\n",
    "    print(\"Model restored.\")\n",
    "    #print(\"Final validation loss:\",sess.run([mean_square],feed_dict={X:InputX1v,Y:InputY1v}))\n",
    "    print(\"output:\",sess.run([output_layer],feed_dict={X:InputX1test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
